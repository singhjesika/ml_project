from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import joblib
import numpy as np

def train_and_save(df, vect_path=VECT_PATH, model_path=MODEL_PATH):
    """Train TF-IDF + Logistic Regression and save model/vectorizer."""
    st.info('Training model â€“ this may take a few seconds depending on dataset size.')

    X = df['cleaned'].values
    y = df['label'].astype(int).values

    # TF-IDF with better balance
    vectorizer = TfidfVectorizer(
        max_features=10000,
        ngram_range=(1, 2),
        min_df=2,
        max_df=0.9
    )
    X_vec = vectorizer.fit_transform(X)

     # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X_vec, y, test_size=0.2, random_state=42, stratify=y
    )

    # Logistic Regression model
    model = LogisticRegression(max_iter=200, class_weight='balanced')
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, digits=4)
    cm = confusion_matrix(y_test, y_pred)

    # Save model & vectorizer
    joblib.dump(model, model_path)
    joblib.dump(vectorizer, vect_path)

    # Debug: show top features for each class
    feature_names = np.array(vectorizer.get_feature_names_out())
    coef = model.coef_[0]
    top_fake = feature_names[np.argsort(coef)[-10:]]
    top_genuine = feature_names[np.argsort(coef)[:10]]

    print("Top words predicting FAKE reviews:", top_fake)
    print("Top words predicting GENUINE reviews:", top_genuine)

    return model, vectorizer, acc, report, cm